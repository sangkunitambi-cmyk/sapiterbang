name: Scrape Anichin Anime List & Video

on:
  push:
    branches:
      - main  # Hanya jalan kalau ada push ke branch main
  workflow_dispatch: # Bisa dijalankan manual dari GitHub UI
  schedule:
    - cron: '0 3 * * *' # Jalan setiap hari jam 3 pagi UTC

jobs:
  scrape:
    runs-on: ubuntu-latest

    permissions:
      contents: write # Izin untuk push hasil scraping kembali ke repo

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      # --- LANGKAH BARU YANG KRUSIAL ---
      - name: Set up Chrome Browser
        uses: browser-actions/setup-chrome@v1
        id: setup-chrome
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          # Kita install selenium dan beautifulsoup4
          pip install selenium beautifulsoup4

      - name: Run scraping script
        run: python scrape_anichin_selenium.py # Nama file script kita ganti
        env:
          # Memberitahu Selenium di mana lokasi Chrome yang sudah di-install
          CHROME_BIN: ${{ steps.setup-chrome.outputs.chrome-path }}

      - name: Commit & Push Results
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email '41898282+github-actions[bot]@users.noreply.github.com'
          git add scraped_result.json
          # Cek apakah ada perubahan sebelum commit
          if git diff --staged --quiet; then
            echo "No changes detected, skipping commit."
          else
            git commit -m "Update: Scraped anime & video list"
            git push
          fi

      - name: Upload debug artifact on failure
        if: failure()
        uses: actions/upload-artifact@v3
        with:
          name: debug-screenshot
          path: debug_screenshot.png # Akan mengupload screenshot jika script gagal
